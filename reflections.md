Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *[2019][]* / *2020*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md
[2019]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2020

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 5](#day-5)
* [Day 6](#day-6)
* [Day 7](#day-7)
* [Day 8](#day-8)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]* / *[Standalone Reflection Page][d01r]*

[d01p]: https://adventofcode.com/2020/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day01.html
[d01r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day01.md

So there's a simple-ish Haskell solution for these problems,

`tails` lets you separate out each item in a list with the list of items after
it:

```haskell
ghci> tails [1,2,3,4]
[1:[2,3,4], 2:[3,4], 3:[4], 4:[]]
```

```haskell
findPair :: [Int] -> Maybe Int
findPair xs = listToMaybe $ do
    x:ys <- tails xs
    y    <- ys
    guard (x + y == 2020)
    pure (x*y)

findTriple :: [Int] -> Maybe Int
findTriple xs = listToMaybe $ do
    x:ys <- tails xs
    y:zs <- tails ys
    z    <- zs
    guard (x + y + z == 2020)
    pure (x*y*z)
```

But this method is a little bit "extra", since we actually don't need to search
all of `ys` for the proper sum...if we pick `x` as `500`, then we really only
need to check if `1520` is a part of `ys`.

So we really only need to check for set inclusion:

```haskell
import qualified Data.IntSet as IS

findPair :: Int -> IS.IntSet -> Maybe Int
findPair goal xs = listToMaybe $ do
    x <- IS.toList xs
    let y = goal - x
    guard (y `IS.member` xs)
    pure (x * y)
```

And our first part will be `findPair 2020`!

You could even implement `findTriple` in terms of `findPair`, using `IS.split`
to partition a set into all items smaller than and larger than a number.
Splitting is a very efficient operation on a binary search tree like `IntSet`:

```haskell
findTriple :: Int -> IS.IntSet -> Maybe Int
findTriple goal xs = listToMaybe $ do
    x <- IS.toList xs
    let (_, ys) = IS.split x xs
        goal'   = goal - x
    case findPair goal' ys of
      Nothing -> empty
      Just yz -> pure (x*yz)
```

But hey...this recursive descent is kind of neat.  We could write a general
function to find any goal in any number of items!

```haskell
-- | Given a number n of items and a goal sum and a set of numbers to
-- pick from, finds the n numbers in the set that add to the goal sum.
knapsack
    :: Int              -- ^ number of items n to pick
    -> Int              -- ^ goal sum
    -> IS.IntSet        -- ^ set of options
    -> Maybe [Int]      -- ^ resulting n items that sum to the goal
knapsack 0 _    _  = Nothing
knapsack 1 goal xs
    | goal `IS.member` xs = Just [goal]
    | otherwise           = Nothing
knapsack n goal xs = listToMaybe $ do
    x <- IS.toList xs
    let goal'   = goal - x
        (_, ys) = IS.split x xs
    case knapsack (n - 1) goal' ys of
      Nothing -> empty
      Just rs -> pure (x:rs)
```

And so we have:

```haskell
part1 :: [Int] -> Maybe Int
part1 = knapsack 2 2020 . IS.fromList

part2 :: [Int] -> Maybe Int
part2 = knapsack 3 2020 . IS.fromList
```

And we could go on, and on, and on!

Definitely very unnecessary, but it does shave my time on Part 2 down from
around 2ms to around 20μs :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 7.149 μs   (6.779 μs .. 7.486 μs)
                     0.978 R²   (0.971 R² .. 0.987 R²)
mean                 7.196 μs   (6.812 μs .. 7.467 μs)
std dev              1.024 μs   (877.4 ns .. 1.230 μs)
variance introduced by outliers: 93% (severely inflated)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 60.32 μs   (56.08 μs .. 65.27 μs)
                     0.977 R²   (0.962 R² .. 0.993 R²)
mean                 61.98 μs   (60.08 μs .. 64.45 μs)
std dev              6.926 μs   (5.163 μs .. 10.18 μs)
variance introduced by outliers: 86% (severely inflated)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]* / *[Standalone Reflection Page][d02r]*

[d02p]: https://adventofcode.com/2020/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day02.html
[d02r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day02.md

Day 2, not too bad for Haskell either :)

There is some fun in parsing here:

```haskell
data Policy = P
    { pIx1  :: Int
    , pIx2  :: Int
    , pChar :: Char
    , pPass :: String
    }

parsePolicy :: String -> Maybe Policy
parsePolicy str = do
    [ixes,c:_,pwd] <- pure $ words str
    [ix1,ix2]      <- pure $ splitOn "-" ixes
    P <$> readMaybe ix1
      <*> readMaybe ix2
      <*> pure c
      <*> pure pwd
```

I used one of my more regular do-block tricks: if you pattern match in a
`Maybe` do-block, then failed pattern matches will turn the whole thing into a
`Nothing`.  So if any of those list literal pattern matches failed, the whole
block will return `Nothing`.

In any case, we just need to write a function to check if a given policy is
valid for either criteria:

```haskell
countTrue :: (a -> Bool) -> [a] -> Int
countTrue p = length . filter p

validate1 :: Policy -> Bool
validate1 P{..} = n >= pIx1 && n <= pIx2
  where
    n = countTrue (== pChar) pPass

validate2 :: Policy -> Bool
validate2 P{..} = n == 1
  where
    n = countTrue (== pChar) [pPass !! (pIx1 - 1), pPass !! (pIx2 - 1)]
```

And so parts 1 and 2 are just a count of how many policies are true :)

```haskell
part1 :: [Policy] -> Int
part1 = countTrue validate1

part2 :: [Policy] -> Int
part2 = countTrue validate2
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 68.36 μs   (68.31 μs .. 68.39 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 68.43 μs   (68.40 μs .. 68.45 μs)
std dev              93.46 ns   (76.39 ns .. 120.0 ns)

* parsing and formatting times excluded

>> Day 02b
benchmarking...
time                 79.58 μs   (77.84 μs .. 81.25 μs)
                     0.998 R²   (0.996 R² .. 0.999 R²)
mean                 80.76 μs   (79.83 μs .. 82.03 μs)
std dev              3.570 μs   (2.862 μs .. 5.070 μs)
variance introduced by outliers: 46% (moderately inflated)

* parsing and formatting times excluded
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]* / *[Standalone Reflection Page][d03r]*

[d03p]: https://adventofcode.com/2020/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day03.html
[d03r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day03.md

Here I'm going to list two methods --- one that involves pre-building a set to
check if a tree is at a given point, and the other involves just a single
direct traversal checking all valid points for trees!

First of all, I'm going to reveal one of my favorite secrets for parsing 2D
ASCII maps!

```haskell
asciiGrid :: IndexedFold (Int, Int) String Char
asciiGrid = reindexed swap (lined <.> folded)
```

This gives you an indexed fold (from the *[lens][]* package) iterating over
each character in a string, indexed by `(x,y)`!

[lens]: https://hackage.haskell.org/package/lens

This lets us parse today's ASCII forest pretty easily into a `Set (Int, Int)`:

```haskell
parseForest :: String -> Set (Int, Int)
parseForest = ifoldMapOf asciiGrid $ \xy c -> case c of
    '#' -> S.singleton xy
    _   -> S.empty
```

This folds over the input string, giving us the `(x,y)` index and the character
at that index.  We accumulate with a monoid, so we can use a `Set (Int, Int)`
to collect the coordinates where the character is `'#'` and ignore all other
coordinates.

Admittedly, `Set (Int, Int)` is sliiiightly overkill, since you could probably
use `Vector (Vector Bool)` or something with `V.fromList . map (V.fromList .
(== '#')) . lines`, and check for membership with double-indexing.  But I was
bracing for something a little more demanding, like having to iterate over all
the trees or something.  Still, sparse grids are usually my go-to data
structure for Advent of Code ASCII maps.

Anyway, now we need to be able to traverse the ray.  We can write a function to
check all points in our line, given the slope (delta x and delta y):

```haskell
countTrue :: (a -> Bool) -> [a] -> Int
countTrue p = length . filter p

countLine :: Int -> Int -> Set (Int, Int) -> Int
countLine dx dy pts = countTrue valid [0..322]
  where
    valid i = (x, y) `S.member` pts
      where
        x = (i * dx) `mod` 31
        y = i * dy
```

And there we go :)

```haskell
part1 :: Set (Int, Int) -> Int
part1 = countLine 1 3

part2 :: Set (Int, Int) -> Int
part2 pts = product $
    [ countLine 1 1
    , countLine 3 1
    , countLine 5 1
    , countLine 7 1
    , countLine 1 2
    ] <*> [pts]
```

Note that this checks a lot of points we wouldn't normally need to check: any y
points out of range (322) for `dy > 1`.  We could add a minor optimization to
only check for membership if `y` is in range, but because our check is a set
lookup, it isn't too inefficient and it always returns `False` anyway.  So a
small price to pay for slightly more clean code :)

So this was the solution I used to submit my original answers, but I started
thinking the possible optimizations.  I realized that we could actually do the
whole thing in a single traversal...since we could associate each of the points
with coordinates as we go along, and reject any coordinates that would not be
on the line!

We can write a function to check if a coordinate is on a line:

```haskell
validCoord
    :: Int      -- ^ dx
    -> Int      -- ^ dy
    -> (Int, Int)
    -> Bool
validCoord dx dy = \(x,y) ->
    let (i,r) = y `divMod` dy
    in  r == 0 && (dx * i) `mod` 31 == x
```

And now we can use `lengthOf` with the coordinate fold up there, which counts
how many traversed items match our fold:

```haskell
countLineDirect :: Int -> Int -> String -> Int
countLineDirect dx dy = lengthOf (asciiGrid . ifiltered tree)
  where
    checkCoord = validCoord dx dy
    tree pt c = c == '#' && checkCoord pt
```

And this gives the same answer, with the same interface!

```haskell
part1 :: String -> Int
part1 = countLineDirect 1 3

part2 :: String -> Int
part2 pts = product $
    [ countLineDirect 1 1
    , countLineDirect 3 1
    , countLineDirect 5 1
    , countLineDirect 7 1
    , countLineDirect 1 2
    ] <*> [pts]
```

Is the direct single-traversal method any faster?

Well, it's complicated, slightly.  There's a clear benefit in the pre-built set
method for part 2, since we essentially build up an efficient structure (`Set`)
that we re-use for all five lines.  We get the most benefit if we build the set
once and re-use it many times, since we only have to do the actual coordinate
folding once.

So, directly comparing the two methods, we see the single-traversal as
faster for part 1 and slower for part 2.

However, we can do a little better for the single-traversal method.  As it
turns out, the lens indexed fold is kind of slow.  I was able to write the
single-traversal one a much faster way by directly just using `zip [0..]`,
without losing too much readability.  And with this *direct* single traversal
and computing the indices manually, we get a much faster time for part 1 (about
ten times faster!) and a slightly faster time for part 2 (about 5 times
faster).  The benchmarks for this optimized version are what is presented
below.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 319.0 μs   (303.8 μs .. 334.5 μs)
                     0.985 R²   (0.979 R² .. 0.991 R²)
mean                 337.7 μs   (329.6 μs .. 343.8 μs)
std dev              23.33 μs   (17.11 μs .. 30.25 μs)
variance introduced by outliers: 63% (severely inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 1.540 ms   (1.452 ms .. 1.628 ms)
                     0.982 R²   (0.973 R² .. 0.992 R²)
mean                 1.599 ms   (1.551 ms .. 1.643 ms)
std dev              155.1 μs   (116.6 μs .. 195.2 μs)
variance introduced by outliers: 70% (severely inflated)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]* / *[Standalone Reflection Page][d04r]*

[d04p]: https://adventofcode.com/2020/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day04.html
[d04r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day04.md

I almost hit the leaderboard today, but hit the 1 minute timeout because I
didn't read carefully enough to treat `cid` as optional ;\_;

Ah well, that's life!

Anyway, there are a lot of great Haskell solutions out there involving parser
combinators and validation of different fields, stuff like that.  My original
solution parsed a map of fields to values, and then validated those values
according to their keys.

But taking a step back from it all, I thought it would be a nice opportunity to
try out the principal of [Parse, Don't Validate][pdv] and see if I can take it
its extremes!  And implementing this in a nice way lead me also to refinement
types with the *[refined][]* library, and also and the [higher-kinded
data][hkd] pattern, supported by  the *[barbies][]* library.

[pdv]: https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/
[hkd]: https://reasonablypolymorphic.com/blog/higher-kinded-data/
[barbies]: https://hackage.haskell.org/package/barbies
[refined]: https://hackage.haskell.org/package/refined

So, what is "Parse, Don't Validate"?  It means: instead of parsing your data
into some structure and then checking if the structure is valid (like my
original parse-a-map-then-check-it), try instead to represent your data in a
structure where it is *imposssible* to represent or create an invalid instance
in the first place.  And so what was originally "validation" is now simply
parsing your data into that correct-by-construction structure.

This seemed like a good candidate for the *[refined][]* library, which gives us
data types that are "literally" impossible to construct unless they are in the
right shape.

```haskell
-- | (a <-> b) will represent the type of an integer between a and b
type a <-> b  = Refined (FromTo a b) Int
-- | (n ** a) will represent the type of a list of a's with exactly n elements
type n ** a   = Refined (SizeEqualTo n) [a]

-- | These come included in the library
refineThrow :: Int -> Maybe (a <-> b)
refineThrow :: [a] -> Maybe (n ** a)
```

Which gives us a good picture for the type of our "correct-by-construction"
passport:

```haskell
data Height =
    HCm (150 <-> 193)
  | HIn ( 59 <->  76)

data Eye = AMB | BLU | BRN | GRY | GRN | HZL | OTH

data Passport = Passport
    { pByr :: 1920 <-> 2002
    , pIyr :: 2010 <-> 2020
    , pEyr :: 2020 <-> 2030
    , pHgt :: Height
    , pHcl :: 6 ** (0 <-> 15)
    , pEcl :: Eye
    , pPid :: 9 ** (0 <-> 9)
    }
```

Et voila!  We now have a passport where it is impossible to construct unless
you have all the correct components!

That's great and all, but...how do we actually parse our data type into this?

One way that could work is to parse each key-value pair into a `Passport` with
all fields blank except for the field corresponding to that key-value pair, and
then combining those optional-field passports into a "certain" passport.

So we can imagine:

```haskell
data PassportMaybe = PassportMaybe
    { pByrMaybe :: Maybe (1920 <-> 2002)
    , pIyrMaybe :: Maybe (2010 <-> 2020)
    , pEyrMaybe :: Maybe (2020 <-> 2030)
    , pHgtMaybe :: Maybe Height
    , pHclMaybe :: Maybe (6 ** (0 <-> 15))
    , pEclMaybe :: Maybe Eye
    , pPidMaybe :: Maybe (9 ** (0 <-> 9))
    }
```

with an appropriate `Monoid` instance that merges known fields together, and a
function like

```haskell
fromPassportMaybe :: PassportMaybe -> Maybe Passport
```

that will only work if all the fields are `Just`.

And hey, we would also maybe like to keep a collection of all the parsers so we
can dispatch them whenever we want...

```haskell
data PassportParser = PassportParser
    { pByrParser :: String -> Maybe (1920 <-> 2002)
    , pIyrParser :: String -> Maybe (2010 <-> 2020)
    , pEyrParser :: String -> Maybe (2020 <-> 2030)
    , pHgtParser :: String -> Maybe Height
    , pHclParser :: String -> Maybe (6 ** (0 <-> 15))
    , pEclParser :: String -> Maybe Eye
    , pPidParser :: String -> Maybe (9 ** (0 <-> 9))
    }
```

And wait a minute ... doesn't part 1 require us to create a passport *without*
validating the strings?  So we also need to create

```haskell
data PassportRaw = PassportRaw
    { pByrRaw :: String
    , pIyrRaw :: String
    , pEyrRaw :: String
    , pHgtRaw :: String
    , pHclRaw :: String
    , pEclRaw :: String
    , pPidRaw :: String
    }
```

And also

```haskell
data PassportRawMaybe = PassportRawMaybe
    { pByrRaw :: Maybe String
    , pIyrRaw :: Maybe String
    , pEyrRaw :: Maybe String
    , pHgtRaw :: Maybe String
    , pHclRaw :: Maybe String
    , pEclRaw :: Maybe String
    , pPidRaw :: Maybe String
    }
```

as well, for the accumulation part?  Wow, this sounds like a horrible idea!

Or...does it?  What if we try the old [higher-kinded data][hkd] trick?

```haskell
data Passport f = Passport
    { pByr :: f (1920 <-> 2002)
    , pIyr :: f (2010 <-> 2020)
    , pEyr :: f (2020 <-> 2030)
    , pHgt :: f Height
    , pHcl :: f (6 ** (0 <-> 15))
    , pEcl :: f Eye
    , pPid :: f (9 ** (0 <-> 9))
    }
  deriving (Generic)
```

Neat, huh?  We now have a flexible data type that can account for all usage
patterns!  For example:

```haskell
-- | the original
type FullPassport = Passport Identity

-- | the optional-field
type PassportMaybe = Passport Maybe

-- | the parser collection
newtype Parser a = Parser { runParser :: String -> Maybe a }
type PassportParser = Passport Parser

-- | the raw strings
newtype Const w a = Const { getConst :: w }
type PassportRaw = Passport (Const String)

 -- | the optional raw strings
type PassportRaw = Passport (Const (Maybe String))
```

We get all of our original desired types, all from a single type definition, by
swapping out the functor `f` we use!  And then we can just use the
*[barbies][]* library to convert between the different formats.  Neat!

Well, what are we waiting for?

First, let's derive all of the instances necessary for our parsing to work,
given by the *barbies* and *one-liner-instances* packages.

```haskell
instance FunctorB Passport
instance ApplicativeB Passport
instance TraversableB Passport
instance ConstraintsB Passport
deriving via GMonoid (Passport f) instance AllBF Semigroup f Passport => Semigroup (Passport f)
deriving via GMonoid (Passport f) instance AllBF Monoid f Passport => Monoid (Passport f)
deriving instance AllBF Show f Passport => Show (Passport f)
```

Now we can write our parsers:

```haskell
newtype Parser a = Parser { runParser :: String -> Maybe a }

passportParser :: Passport Parser
passportParser = Passport
    { pByr = Parser $ refineThrow <=< readMaybe
    , pIyr = Parser $ refineThrow <=< readMaybe
    , pEyr = Parser $ refineThrow <=< readMaybe
    , pHgt = Parser $ \str ->
                let (x, u) = span isDigit str
                in  case u of
                      "cm" -> fmap HCm . refineThrow =<< readMaybe x
                      "in" -> fmap HIn . refineThrow =<< readMaybe x
                      _    -> Nothing
    , pHcl = Parser $ \case
                '#':n -> refineThrow =<< traverse readHex n
                _     -> Nothing
    , pEcl = Parser $ readMaybe . map toUpper
    , pPid = Parser $ refineThrow <=< traverse (refineThrow <=< readMaybe . (:[]))
    }
  where
    readHex c
      | isHexDigit c = refineThrow (digitToInt c)
      | otherwise    = Nothing
```

The usage of `refineThrow` means that we use the machinery already defined in
the *[refined][]* library to automatically check that our data is within the
given ranges...no need for manual range checking!

Now we can load a single `key:val` token into a passport that is *empty* (all
fields are `Const Nothing`) *except for* the value at the seen key

```haskell
-- | Load a single "key:val" token into a passport
loadPassportField :: String -> Passport (Const (Maybe String))
loadPassportField str = case splitOn ":" str of
    [k,v] -> case k of
      "byr" -> mempty { pByr = Const (Just v) }
      "iyr" -> mempty { pIyr = Const (Just v) }
      "eyr" -> mempty { pEyr = Const (Just v) }
      "hgt" -> mempty { pHgt = Const (Just v) }
      "hcl" -> mempty { pHcl = Const (Just v) }
      "ecl" -> mempty { pEcl = Const (Just v) }
      "pid" -> mempty { pPid = Const (Just v) }
      _     -> mempty
    _     -> mempty
```

```haskell
ghci> loadPassportField "eyr:1234"
Passport
  { pByr = Const Nothing
  , pIyr = Const Nothing
  , pEyr = Const (Just "1234")
  , pHgt = Const Nothing
  , pHcl = Const Nothing
  , pEcl = Const Nothing
  , pPid = Const Nothing
  }
```

Now we can parse a field in its entirety by using `bzipWith` (from *barbies*),
to "zip together" a `Passport Parser` and `Passport (Const (Maybe String))`
with a given function that tells how to merge the values in any two fields.

```haskell
parsePassportField :: String -> Passport Maybe
parsePassportField = bzipWith go passportParser . loadPassportField
  where
    go p (Const x) = runParser p =<< x
```

In the above, `go` is run between each matching field in the `Passport Parser`
and the `Passport (Const (Maybe String))`, and the overall effect is that each
string is run with the appropriate parser for its field.

```haskell
ghci> parsePassportField "eyr:2025"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Just (refined 2025)
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Nothing
  , pPid = Nothing
  }
ghci> parsePassportField "eyr:2050"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Nothing
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Nothing
  , pPid = Nothing
  }
```

And the way the `Monoid` instance works, we can just combine two `Passport
Maybe`s with `<>`:

```haskell
ghci> parsePassportField "eyr:2025" <> parsePassportField "ecl:brn"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Just (refined 2025)
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Just BRN
  , pPid = Nothing
  }
```

Which gives us a nice function to parse a whole passport, with the help of
`btraverse` to flip a `Passport Maybe` into a `Maybe (Passport Identity)`

```haskell
parsePassport :: String -> Maybe (Passport Identity)
parsePassport = btraverse (fmap Identity)
              . foldMap parsePassportField
              . words
```

The result of `foldMap parsePassportField . words` is a `Passport Maybe`, and
`btraverse` "pulls out" all of the `Just` fields and returns a `Passport
Identity` if all of the fields are `Just`, failing with `Nothing` if any of the
fields are `Nothing`.

And...that's it for part 2!

```haskell
-- | Get a list of all valid passports.
part2 :: String -> [Passport Identity]
part2 = mapMaybe parsePassport . splitOn "\n\n"
```

This works because we know that if we have a `Passport Identity`, we *know* it
has to be a valid passport.  It's physically impossible to create one that
isn't valid!

**All hail "Parse, Don't Validate"!**

And part 1 is a fun diversion: instead of a `Passport Identity`, we want to
parse into a `Passport (Const String)` instead.  The mechanics are pretty much
the same:

```haskell
loadPassport :: String -> Maybe (Passport (Const String))
loadPassport = btraverse (\(Const x) -> Const <$> x)
             . foldMap loadPassportField
             . words
```

The result of `foldMap loadPassportField` is a `Passport (Const (Maybe
String))`, and so `btraverse` will pull out all the `Just`s again, returning a
`Passport (Const String)` and failing if any of those values were `Nothing`s.
Note the sliiight abuse of the `Monoid` instance for `Maybe`, which combines
strings by concatenation.  But we're more concerned about whether or not it is
present than the actual contents of the string.

Anyway, here's wonderwall.

```haskell
-- | Get a list of all complete passports field string values.
part1 :: String -> [Passport (Const String)]
part1 = mapMaybe loadPassport . splitOn "\n\n"
```


### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 1.528 ms   (1.434 ms .. 1.686 ms)
                     0.960 R²   (0.946 R² .. 0.977 R²)
mean                 1.678 ms   (1.618 ms .. 1.730 ms)
std dev              201.5 μs   (174.5 μs .. 272.1 μs)
variance introduced by outliers: 78% (severely inflated)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 4.882 ms   (4.647 ms .. 5.072 ms)
                     0.982 R²   (0.969 R² .. 0.992 R²)
mean                 4.814 ms   (4.691 ms .. 4.902 ms)
std dev              371.2 μs   (271.7 μs .. 467.7 μs)
variance introduced by outliers: 48% (moderately inflated)

* parsing and formatting times excluded
```



Day 5
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day05.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d05p]* / *[Code][d05g]* / *[Rendered][d05h]* / *[Standalone Reflection Page][d05r]*

[d05p]: https://adventofcode.com/2020/day/5
[d05g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day05.hs
[d05h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day05.html
[d05r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day05.md

So, compared to yesterday's, this was decently chill :)

The main insight here probably is that the puzzle is just describing that the
seat ID's are straight up binary notation for numerals, with F/L representing
what is traditionally 0, and B/R representing what is traditionally 1.  So we
can use any of our binary parsers from the standard libraries, or we can just
directly pull it into binary.

```haskell
seatId :: String -> Int
seatId = foldl' iGuessWe'reDoingThis 0
  where
    iGuessWe'reDoingThis n = \case
      'B' -> 2*n+1
      'R' -> 2*n+1
      _   -> 2*n
```

A nice one-pass way to find the missing seat ID is to realize that if we sum
all the numbers from min to max, and sum all of our lists's seat id's, then the
difference is the missing number.  Luckily there's a nice closed-form solution
for the sum of all numbers in a given range (the sum of numbers from `a` to `b`
is ``b*(b+1)`div`2 - a*(a-1)`div`2``), so we can do all of this in a single
pass using the *[foldl][]* library

[foldl]: https://hackage.haskell.org/package/foldl

```haskell
{-# LANGUAGE ApplicativeDo #-}
import qualified Control.Foldl as F

findHole :: F.Fold Int (Maybe Int)
findHole = do
    mn <- F.minimum
    mx <- F.maximum
    sm <- F.sum
    pure $
      missingItem <$> mn <*> mx <*> pure sm
  where
    missingItem mn mx sm = totalSum - sm
      where
        totalSum = mx*(mx+1)`div`2 - mn*(mn-1)`div`2
```

A `F.Fold Int (Maybe Int)` folds a list of `Int`s into a `Maybe Int`.  You can
run it with `F.fold :: F.Fold a b -> [a] -> b`.

I really like the *foldl* library because it lets you build a complex
single-pass fold by combining multiple simple single-pass folds (like
`F.minimum`, `F.maximum`, `F.sum`) using an Applicative interface.  We need to
do a bit of wrangling with the `Maybe`s because `F.minimum` and `F.maximum`
each return `Maybe Int`.

And that's more or less it!  We can actually represent the entire thing as a
fold if we use `F.premap`, to pre-map a fold...


```haskell
F.premap                 :: (c -> a) -> F.Fold a b -> F.Fold c b

-- "pre-apply" `setId` so we fold over a string instead
F.premap seatId findHole :: F.Fold String (Maybe Int)
```

And...that's enough to do it all in a single pass!

```haskell
part1 :: [String] -> Maybe Int
part1 = F.fold $ F.premap seatId F.maximum

part2 :: [String] -> Maybe Int
part2 = F.fold $ F.premap seatId findHole
```

Bonus: I was tipped off that the 3rd from last digit of F/L are 1, while the
same digit of B/R are 0:

```haskell
ghci> (.&. 1) . (`shiftR` 2) . ord <$> "FLBR"
[1,1,0,0]
```

So we can actually use this for `seatId` to get a slight speed boost and help
out the branch predictor maybe:

```haskell
import Data.Bits

seatId :: String -> Int
seatId = foldl' iGuessWe'reDoingThis 0
  where
    iGuessWe'reDoingThis n c =
      2 * n + (complement (ord c) `shiftR` 2) .&. 1
```


### Day 5 Benchmarks

```
>> Day 05a
benchmarking...
time                 23.26 μs   (23.23 μs .. 23.30 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 23.27 μs   (23.25 μs .. 23.33 μs)
std dev              120.4 ns   (40.75 ns .. 238.7 ns)

* parsing and formatting times excluded

>> Day 05b
benchmarking...
time                 24.62 μs   (24.35 μs .. 24.79 μs)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 24.68 μs   (24.55 μs .. 24.79 μs)
std dev              480.0 ns   (289.1 ns .. 651.3 ns)
variance introduced by outliers: 17% (moderately inflated)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]* / *[Standalone Reflection Page][d06r]*

[d06p]: https://adventofcode.com/2020/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day06.html
[d06r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day06.md

Another day that is fairly straightforward in Haskell, I feel!  But in other
languages that support functional approaches, it should be straightforward as
well.

The answer involves lists of groups of responses:

```haskell
import           Data.List.NonEmpty
import           Data.Set
import qualified Data.List.NonEmpty as NE
import qualified Data.Set           as S

type Response = Set Char
type Group    = NonEmpty Response

parseAnswers :: Set Char -> [Group]
parseAnswers = mapMaybe ((fmap . fmap) S.fromList . NE.nonEmpty . lines)
             . splitOn "\n\n"
```

And now we just need to decide how to aggregate each group.  For part 1, this
requires a set union between every `Response` in a `Group`:

```haskell
part1 :: [Group] -> Int
part1 = sum . map (S.size . foldr1 S.union)
```

(`foldr1` here is safe because we have a non-empty container)

And for part 2, this requires a set intersection between every `Response` in a
`Group`:


```haskell
part2 :: [Group] -> Int
part2 = sum . map (S.size . foldr1 S.intersection)
```

That's it!


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 145.0 μs   (137.0 μs .. 152.1 μs)
                     0.985 R²   (0.980 R² .. 0.993 R²)
mean                 142.7 μs   (139.0 μs .. 146.0 μs)
std dev              12.22 μs   (10.47 μs .. 14.09 μs)
variance introduced by outliers: 75% (severely inflated)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 154.7 μs   (152.5 μs .. 157.4 μs)
                     0.993 R²   (0.978 R² .. 0.999 R²)
mean                 153.4 μs   (149.9 μs .. 161.0 μs)
std dev              15.76 μs   (8.020 μs .. 28.24 μs)
variance introduced by outliers: 81% (severely inflated)

* parsing and formatting times excluded
```



Day 7
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day07.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d07p]* / *[Code][d07g]* / *[Rendered][d07h]* / *[Standalone Reflection Page][d07r]*

[d07p]: https://adventofcode.com/2020/day/7
[d07g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day07.hs
[d07h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day07.html
[d07r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day07.md

Another AoC staple, a graph search that can be solved with recursive knot
tying!  The last one I remember off the top of my head was [2019 Day
6][2019d06].

[2019d06]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-6

Here we can represent a graph as a map of vertices to other vertices, with an
edge value:

```haskell
type Graph v e = Map v (Map v e)
```

Exercise is left to the reader to parse our dataset into a `Graph String Int`,
a graph of bags to bags with `Int` edges.

Because our map has no cycles, we can take advantage of recursive knot tying to
"fold up" all children and sub-children.

For example, part 1 can be written as:

```haskell
allDescendants :: Ord v => Graph v e -> Map v (Set v)
allDescendants gr = descendantMap
  where
    descendantMap = gr <&>
      M.foldMapWithKey (\v _ -> S.insert v (M.findWithDefault S.empty v descendantMap))

-- note: (<&>) is flip fmap
```

Here we "assume" we already have a fully-featured `Map v (Set v)` map of
vertices to all their descendants, and then build `descendantMap` in terms of
it.  For every vertex `v` in the `Map v e` directly underneath a given vertex,
`v` is a descendant, and also all of `v`'s descendants (which we find by
looking things up in `descendantMap`, the map of all descendants).

Oh, um...oops, this found all the descendants, but we want all of the
ancestors.  So we have to flip the graph if we want to use this.

```haskell
flipGraph :: Ord v => Graph v e -> Graph v e
flipGraph mp = M.fromListWith M.union
    [ (m, M.singleton n e)
    | (n, ms) <- M.toList mp
    , (m, e ) <- M.toList ms
    ]

allAncestors :: Ord v => Graph v e -> Map v (Set v)
allAncestors = allDescendants . flipGraph
```

And so that leaves Part 1 as:

```haskell
part1 :: Graph String (String Int) -> Maybe (Set String)
part1 = M.lookup "shiny gold" . allAncestors
```

Part 2 we can do a similar way, by "assuming" we have a map of all vertices to
their "usage count", and looking things up to build it:

```haskell
usageCounts :: Ord v => Graph v Int -> Map v Int
usageCounts gr = usageMap
  where
    usageMap = gr <&> \neighbors -> sum
      [ n * (M.findWithDefault 0 v usageMap + 1)
      | (v, n) <- M.toList neighbors
      ]
```

So to find the total usage of each bag, we look under each `(v, Int)` pair in the
`Map v Int` underneath a given vertex, look up the usage of that `v` (by
looking it up in `usageMap`), add 1 (because the bag itself is used), and
multiply by `n`, the number of times the full contents of the bag is used.

And so Part 2 is:

```haskell
part2 :: Graph String (String Int) -> Maybe Int
part2 = M.lookup "shiny gold" . usageCounts
```

If we stare at the two implementations, we note that both are pretty much the
same overall structure: we are accumulating some sort of fold over all
descendants of a given node.  If we "outsource" this accumulation as a monoidal
one (for part 1, it's `Set` union, and for part 2, it's `Sum Int` addition), we
can needlessly hyper-generalize this to fold over any `Monoid` instance.

```haskell
-- | Recursively fold up a monoid value for each vertex and all of its
-- children's monoid values.  You can transform the value in-transit before it
-- is accumulated if you want.
foldMapGraph
    :: (Ord v, Monoid m)
    => (v -> m)         -- ^ embed the vertex
    -> (e -> m -> m)    -- ^ transform with edge before it is accumulated
    -> Graph v e
    -> Map v m
foldMapGraph f g gr = res
  where
    res = gr <&>
      M.foldMapWithKey (\s v -> f s <> foldMap (g v) (M.lookup s res))

allDescendants :: Ord v => Graph v e -> Map v (Set v)
allDescendants = foldMapGraph
    S.singleton     -- the node is embedded as itself
    (\_ -> id)      -- ignore the edge

usageCounts :: Ord v => Graph v Int -> Map v (Sum Int)
usageCounts = foldMapGraph
    (const 0)                   -- ignore the nodes
    (\n x -> Sum n * (x + 1))   -- the edge multiplies the accumulator plus one
```

That's the curse of Haskell, I guess?  If you write these things you can't help
but notice the common patterns, and you somehow wind up trying to figure out
the higher-order function that can abstract over them, even though you know you
don't need to :)


### Day 7 Benchmarks

```
>> Day 07a
benchmarking...
time                 2.206 ms   (2.167 ms .. 2.272 ms)
                     0.971 R²   (0.920 R² .. 0.999 R²)
mean                 2.192 ms   (2.142 ms .. 2.380 ms)
std dev              291.8 μs   (57.37 μs .. 610.2 μs)
variance introduced by outliers: 79% (severely inflated)

* parsing and formatting times excluded

>> Day 07b
benchmarking...
time                 18.64 μs   (18.43 μs .. 19.00 μs)
                     0.998 R²   (0.994 R² .. 1.000 R²)
mean                 18.82 μs   (18.69 μs .. 19.13 μs)
std dev              662.6 ns   (331.6 ns .. 1.140 μs)
variance introduced by outliers: 41% (moderately inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]* / *[Standalone Reflection Page][d08r]*

[d08p]: https://adventofcode.com/2020/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day08.html
[d08r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day08.md

Nothing tooooo complicated about today's, I feel: it is another staple of
AoC --- simulating a virtual machine! :)  Only this time our program is
separate from our memory, so we don't have any actual self-modifying code.
However, my guard is up: this might turn into one of those soon in another day.

At least, there are some interesting things we can do to prepare for a
potential switch to different requirements in a later day (with the `Ixed`)
typeclass, and also a nice way to handle the perturbations in Part 2 using
`holesOf` and lens traversal composition.

My main program was a sequence of `Command`:

```haskell
data Instr = NOP | ACC | JMP

type Command = (Instr, Int)
```

But, what container should we use for these?

1.  `[Command]`: Nope, bad, literally no reason to ever use this except for
    O(1) push and pop.  The main operation here is indexing, and it's O(i) on
    the index.
2.  `Vector Command`: Very fast indexing (O(1) on the index), but very bad for
    any sort of addition of new instructions in-flight if that comes up in the
    future.  But good enough for now.
3.  `Seq Command`: Efficient indexing (O(1) on the index), and very good for
    adding new instructions to either end (or even in the middle) in-flight if
    it comes to that.
4.  `IntMap Command`: Efficient indexing (O(1) on the index), very good for
    adding new instructions to either end, and also good for a sparse program
    bank if it ever comes to that.

*Luckily*, we can get a common interface for all four of these options by using
the `Ixed` typeclass from the *lens* library, which abstracts over different
"indexable" things.  You'd get a safe index with `xs ^? ix i`.  So whenever
possible, I've written all my code to work generally over all four of these in
case I have to swap quickly in the future.

One theoretical nice container would actually be the `PointedList` data type
(one implementation is in the *[pointedlist][]* library).  This is because all
of our addressing is relative, so instead of storing a "current index", we
could just always point towards the focus of the tape, and shift the tape left
or right for `JMP`.

[pointedlist]: https://hackage.haskell.org/package/pointedlist-0.6.1/docs/Data-List-PointedList.html

However, this is kind of difficult to adapt to work in a uniform interface to
the other four types...so, goodbye theoretical nicety, sacrificed in the name
of adaptivity :'(

So for my solution I used `Vector`, which has just the API necessary without
the extra flexibility that `Seq` and `IntMap` offer, since we don't need it!
But, just know that things could be swapped at any time, thanks to the magic
(or horror, depending on your point of view) of typeclasses.

On the other hand, if we separate out the index from a fixed container, it does
make the state a lot simpler.  It means that our state is really only the
current pointer and the accumulator:

```haskell
data CState = CS { csPtr :: !Int, csAcc :: !Int }

initialCS :: CState
initialCS = CS 0 0

runCommand :: Vector Command -> CState -> Maybe CState
```

So our actual program becomes a very tight `CState -> Maybe CState` loop --
very efficient because the state is only a tuple!  That means that we can
simply chain things using `iterateMaybe` go get a list of all successive
states:

```haskell
-- | A handy utility function I keep around
iterateMaybe :: (a -> Maybe a) -> a -> [a]
iterateMaybe f = go
  where
    go x = x : case f x of
      Nothing -> []
      Just y  -> go y

allStates :: Vector Command -> [CState]
allStates cmd = iterateMaybe (runCommand cmd) initialCS
```

So now we have a generator of all the states a given program bank will ever
output.  For part 1, we just need to find a loop.  Luckily I have another handy
utility function that scans a list and reports the first time a projection
function's result is repeated

```haskell
-- | Lazily find the first repeated projection.
firstRepeatedBy :: Ord a => (b -> a) -> [b] -> Maybe b
firstRepeatedBy f = go S.empty
  where
    go seen (x:xs)
      | f x `S.member` seen = Just x
      | otherwise           = go (f x `S.insert` seen) xs
    go _ []     = Nothing

part1 :: Vector Command -> Maybe CState
part1 cmd = firstRepititionBy csPtr states
  where
    states = iterateMaybe (runCommand cmd) inititialCS
```

Now all that's left is to actually implement `runCommand`!

```haskell
runCommand
    :: Vector Command
    -> CState
    -> Maybe CState
runCommand cmds cs = (cmds ^? ix (csPtr cs)) <&> \case
    (NOP, _) -> cs { csPtr = csPtr cs + 1 }
    (ACC, i) -> cs { csPtr = csPtr cs + 1, csAcc = csAcc cs + i }
    (JMP, i) -> cs { csPtr = csPtr cs + i }

-- note: <&> is flip fmap
```

And the nice thing about it is that if we leave off the type annotation of
`runCommand`, we actually get a really nice polymorphic type if we ask GHC what
it expects:

```haskell
runCommand
    :: (Ixed t, Index t ~ Int, IxValue t ~ (Instr, Int))
    => t
    -> CState
    -> Maybe CState
```

This is the fully polymorphic signature that you get just from using `cmds ^?
ix (csPtr cs)`.  It says that you can use this on *any* program bank `t` that's
an instance of `Ixed`, as long as its index type is `Int` and the value at that
index is a `(Instr, Int)`.  Nothing about the typeclasses here is inherently
lensy, it's just a typeclass (like any other) to abstract over common
interfaces that many types might have.  In this fully polymorphic signature, we
can use this on `Vector Command`, `[Command]`, `Seq Command`, and `IntMap
Command`, as we wish to in the future if the need comes up.

For part 2 we can take advantage of some *actual* lens/optics magic, by using
`holesOf`:

```haskell
holesOf
    :: Traversal' s a
    -> s
    -> [Pretext (->) a a s]
```

The type is definitely scary, but `holesOf` is saying:

1.  Give me a specification of which holes you want to poke (`Traversal' s a`,
    a value `s` with holes `a`)
2.  ... and an item you want to poke the holes in (`s`)
3.  ... and I'll return to you a list of continuations (`Pretext (->) a a (t
    a)`), each one allowing you to edit a different hole in `s`.

`Pretext` is a bit of a complicated type, but the main interface you would use
it with is:

```haskell
peeks :: (a -> a) -> Pretext (->) a a s -> s
```

`peeks` as for a function you would want to run on a hole (the `a -> a`), the
continuation you got from `holesOf`, and then returns the "modified" `s`,
modified according to that transformation you ran on that hole.

(thanks to *mniip* on freenode IRC for pointing out how these two work together
to me!)

Every item in the list returned by `holesOf` corresponds to a different hole,
so for example:

```haskell
ghci> map (peeks negate) (holesOf traverse [1,2,3]
[ [-1, 2, 3]
, [ 1,-2, 3]
, [ 1, 2,-3]
]
```

The `traverse :: Traversal' [a] a` is a `Traversal` that specifies the "holes"
of a list `[a]` to be each item `a` in that list.  And so `holesOf traverse
[1,2,3]` will return three `Pretext`s: one corresponding to modifying each item
in the list individually.

`peeks negate` on each of the three items returned by `holesOf traverse
[1,2,3]` will return the modified list, each with a single hole edited by
`negate`.

In our case, instead of `negate`, we can use a `flipInstr` that flips `NOP` to
`JMP` and `JMP` to `NOP`:

```haskell
flipInstr :: Command -> Command
flipInstr = \case
    NOP -> JMP
    ACC -> ACC
    JMP -> NOP
```

And now `peeks flipInstr` will do the right thing:

```haskell
ghci> map (peeks flipInstr) (holesOf traverse [NOP,ACC,JMP,JMP])
[ [JMP,ACC,JMP,JMP]
, [NOP,ACC,JMP,JMP]
, [NOP,ACC,NOP,JMP]
, [NOP,ACC,JMP,NOP]
]
```

An extra coolio thing is that traversals compose with `.`, so we can actually
use a traversal `_1` (here, `Traversal' (a,b) a`, which says the single "hole"
in an `(a,b)` is the first item in the tuple) to be more nuanced with our hole
selection:

```haskell
ghci> map (peeks flipInstr)
        (holesOf (traverse . _1) [(NOP,1),(ACC,2),(JMP,3),(JMP,4)])
[ [(JMP,1),(ACC,2),(JMP,3),(JMP,4)]
, [(NOP,1),(ACC,2),(JMP,3),(JMP,4)]
, [(NOP,1),(ACC,2),(NOP,3),(JMP,4)]
, [(NOP,1),(ACC,2),(JMP,3),(NOP,4)]
]
```

Neat!

With that we can fully write `part2`: for each perturbation, check if there is
a loop.  If there is a loop, this ain't it.  If there isn't a loop, then we hit
the jackpot: return the last item in our list of seen states, as that's the
last state before termination.

```haskell
part2 :: Vector Command -> Maybe CState
part2 cmds0 = listToMaybe
    [ res
    | cmds <- peeks flipInstr <$> holesOf (traverse . _1) cmds0
    , let states = iterateMaybe (runCommand cmds) initialCS
    , res  <- case firstRepeatedBy csPtr stats of
        Nothing -> [last states]    -- loop found
        Just _  -> []               -- no loop found
    ]
```


### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 32.08 μs   (30.57 μs .. 33.00 μs)
                     0.989 R²   (0.982 R² .. 0.995 R²)
mean                 31.92 μs   (30.95 μs .. 33.04 μs)
std dev              3.533 μs   (2.814 μs .. 5.616 μs)
variance introduced by outliers: 87% (severely inflated)

* parsing and formatting times excluded

>> Day 08b
benchmarking...
time                 5.623 ms   (5.284 ms .. 6.125 ms)
                     0.927 R²   (0.827 R² .. 0.992 R²)
mean                 6.234 ms   (6.023 ms .. 6.617 ms)
std dev              898.8 μs   (445.8 μs .. 1.576 ms)
variance introduced by outliers: 75% (severely inflated)

* parsing and formatting times excluded
```

